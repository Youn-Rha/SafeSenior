# Documents
* 각종 프로그램 설명 및 관련 자료를 기술
* 처음 사용자는 DataCollecter 부터 확인할 것

### DataCollecter
* [README](./dataCollect/README.md)

### Visualizer
* [README](./UI/README.md)

### AI
* [README](./ai/README.md)


## [Programming Guidance](./guidance/README.md)
* 프로그램을 수정할 경우 위 링크의 가이드라인 참조하는 것을 추천


## 향후 구현방향
* [mmWave_MSc](https://github.com/AsteriosPar/mmWave_MSc?tab=readme-ov-file)
* [MARS](https://github.com/SizheAn/MARS)
* 위 두 링크 참조하여 진행
    1. 지도 클러스터링에 기반한 인원 구별 클러스터링 구현 (RNN + convolutional 구현 등)
    2. 더 긴 시퀸스 사용하여 정확해진 낙상 및 자세 인식 모델 구현
    3. (optional) MARS의 스켈레톤 매핑 적용

### 현재 시스템의 한계 및 극복방향
* 센서가 판별하는 사람에 AI가 판별한 상태를 표시
    * 센서가 판별하는 인원과 AI가 판별한 인원의 불일치 문제
    * 지도 클러스터링 통해 직접 사람의 위치를 추론
* DBSCAN에 기반한 비지도 클러스터링이 레이더로 얻은 point cloud data에 적합하지 않은 문제
    * 이동한 물체에 대한 도플러 편이를 인식하는 시스템 특성상, 움직임이 끊기는 경우 생긴다
    * 이러한 경우 동일한 인원을 지속적으로 추적하는데 어려움 존재
    * point cloud에 최적화된 지도 클러스터링을 학습할 필요가 있음
* 클러스터링의 낮은 신체 판별 능력과 충분한 sequence 모으지 못하는 한계
    * 움직임 멈추게 되면, sequence가 끊기게 된다 -> 임의 해결하였으나 지도 클러스터링 통한 해결 필요
    * DBSCAN 방식으로는 신체를 판별하는 능력이 부족하다
    * 사람의 움직임을 지속적으로 tracking하는 능력의 부족 : 현재는 가장 근접한 클러스터에 할당하는 방식
    * 팔, 몸통, 다리, 머리 등의 단위로 인식하도록 DBSCAN의 파라미터를 튜닝하고, 이를 하나의 사람이 되게 합쳐 지도학습 데이터 마련
    * 해당 데이터를 학습한 RNN 기반 클러스터링 모델을 통해 위에서 기술한 문제 해결을 기대

### 진행순서
* 우선적으로 예상 가능한 다양한 시나리오에 대한 다량의 데이터 수집이 필요 (n분 등의 목표 시간 설정이 필요)
    * dataCollect 프로그램을 활용
    * 카메라와 센서를 동시에 사용하여 촬영하여 향후 labeling에 활용
    * 지도 클러스터링 및 스켈레톤화 학습, 다양한 시나리오에 대한 데이터 수집
* Labeling Tool을 사용하여 지도 클러스터링에 필요한 학습 데이터를 생성
    * 지도 클러스터링 학습하여 cloud point가 중간에 끊기더라도 연속적으로 객체 인식 가능하게 구현 필요
* 지도 클러스터링이 완성되면 다양한 시나리오에 대한 낙상 및 자세 인식 모델의 구현 시도
* 이상 상황을 감지하는 기능 또한 병행하여 구현하는 것 고려

### 역할분담 (제안)
* 클러스터링 모델 학습을 위한 데이터는 팀원 전원이 수행 (프로젝트 초기에 다량으로 수집 필요)
* Visualizer 수정할 PyQt 담당자 1명
* 이외 모든 인원은 AI 담당
* PyQt나 AI 다루지 못하는 인원이 있다면
    * 클러스터링 이후 자세 판별용 학습 데이터를 수집
    * 공간에 따른 센서 튜닝 정보인 cfg 파일 생성
    * 센서에 들어오는 노이즈와 tracking 관련 알고리즘 탐색
        * Kalman Filter와 유사한 기능
    * 속도 느린 기존 sci-kit learn의 DBSCAN을 직접 구현하여 최적화